# Cursor Rules — Knostic CSV Manager (LLM engineer working agreement)

**Purpose**
This file contains a working agreement and actionable workflow instructions for an LLM agent (Cursor) to implement the **Knostic CSV Data Management Web App** as a Senior Full‑Stack Engineer would. The LLM should act incrementally, produce production-quality code, run tests, and create a clear git commit after each *completed* stage.

> **Goal:** deliver a Node.js + React app that supports upload, editable tables, validation of `strings.csv` against `classifications.csv`, export, tests, Docker, and deployment.

---

## High-level rules (system prompt style)

You are a *senior full-stack engineer* with years of experience. Follow these rules strictly:

1. **Work incrementally.** Break tasks into small, reviewable stages. After completing a stage that produces runnable/tests-passing code, generate a git commit with a Conventional Commit style message and *commit only the files you changed for that stage*.
2. **Do not commit broken tests.** Run the unit tests you add. If tests fail, fix them before committing or revert work and explain why.
3. **Prefer clarity over cleverness.** Write clean, documented, testable code. Add brief comments for non-obvious decisions.
4. **Follow best practices** for security, performance, and maintainability (validate inputs, avoid leaking secrets, handle errors gracefully, keep code modular, use environment variables for config, add logging where appropriate).
5. **Add tests alongside features.** Each feature must include unit tests for core logic (validation, CSV parsing/writing, table helpers). Use Jest (backend) and Vitest/React Testing Library (frontend) examples.
6. **Use meaningful commit messages** (Conventional Commits). Each commit should describe a single logical stage.
7. **Document run & build steps** in `README.md`. Update README as features are added.
8. **Do not rely on filenames** for validation — derive roles from column headers or allow explicit file-role mapping in UI.

---

## Stages & expected commits

For each stage below: implement code, add tests, run tests, then commit. Use the suggested commit message prefix.

### Stage 00 — Repository bootstrap

* Initialize repository layout: `backend/`, `frontend/`, root `Dockerfile`, `README.md`, `.gitignore`.
* Add basic package.json files (with start/build/test scripts).
* Add lint/prettier config if desired.

**Commit:** `chore: initialize repo scaffold (backend + frontend + docker + README)`

---

### Stage 01 — Backend: CSV parsing + upload endpoints

* Implement Express server with routes: `/api/csv/upload`, `/api/csv/validate`, `/api/csv/export`.
* Use `multer` (memory storage) and `csv-parser` or `csv-parse` to parse buffers.
* Implement parsing helper that normalizes headers (accepts `SubTopic`, `Subtopic`, `Sub Topic`, etc.).
* Add unit tests for parse helper using Jest.

**Acceptance criteria:** parse helper returns arrays of objects with normalized keys; upload returns parsed JSON.

**Commit:** `feat(backend): add CSV upload and parsing endpoints + header normalization`

---

### Stage 02 — Backend: Validation logic & tests

* Implement validation function: for each `strings` row ensure the tuple `(Topic, SubTopic, Industry)` exists in `classifications` (case-insensitive, trimmed).
* Return `invalidRows` including `rowIndex` and `reason`.
* Add unit tests covering valid/invalid combos, blank/missing fields, header variants.

**Commit:** `feat(backend): add strings vs classifications validation + tests`

---

### Stage 03 — Backend: CSV export endpoint

* Implement an `/api/csv/export` that accepts JSON rows + headers and returns a CSV download (stream with `fast-csv`).
* Add tests to assert CSV output shape for given rows/headers.

**Commit:** `feat(backend): add CSV export streaming endpoint + tests`

---

### Stage 04 — Frontend: Basic upload UI & parsed preview

* Scaffold React app (Vite recommended). Create `CsvUploader` component that accepts multiple files and shows parsed preview.
* Send `multipart/form-data` to `/api/csv/upload` and receive parsed JSON.
* Add mapping UI allowing user to map uploaded file -> role (strings / classifications) when header heuristics are ambiguous.
* Add unit tests for parsing + mapping heuristics (Vitest + RTL).
* use shad ui and tialwind css

**Commit:** `feat(frontend): add CSV uploader and file-role mapping UI`

---

### Stage 05 — Frontend: Editable tables

* Implement `EditableTable` component with inline cell editing, add/delete rows, and controlled props. Keep simple inputs for most columns; large `Prompt`/`Risks` fields can be `textarea` in-cell.
* Track edited rows in state and expose `onChange(rows)`.
* Add unit tests for editing, add/delete, and change callbacks.

**Commit:** `feat(frontend): add editable table component (edit/add/delete rows) + tests`

---

### Stage 06 — Frontend: Validation flow & UI feedback

* Wire `Validate` button to POST `/api/csv/validate` with current rows.
* If invalid, prevent save/export, highlight invalid rows visually and show `reason` messages (row-level).
* If valid, allow export and show success toast.
* Add tests verifying the UI highlights invalid rows and shows error messages.

**Commit:** `feat(frontend): add validation flow and error highlighting + tests`

---

### Stage 07 — Frontend: Export buttons

* Implement `ExportButtons` that POST `/api/csv/export` to get CSV blobs and trigger downloads.
* Preserve header order when exporting; allow user to edit column order if needed.
* Add simple tests that stub API and ensure download logic is invoked.

**Commit:** `feat(frontend): add local CSV export buttons`

---

### Stage 08 — Tests, CI, and code quality

* Add GitHub Actions workflow: run backend Jest tests and frontend Vitest tests, lint, and build step.
* Ensure `npm test` scripts exist and pass.

**Commit:** `chore(ci): add GitHub Actions for tests + build`

---

### Stage 09 — Dockerize & deploy

* Add multi-stage Dockerfile that builds frontend and serves it via backend static `public` folder or uses a simple static server.
* Verify the container runs both backend server and static frontend on environment `PORT` (default 4000).
* Add `railway.md` snippet with steps for Railway deploy or sample `Procfile` if needed.

**Commit:** `chore(docker): add multi-stage Dockerfile and deploy docs`

---

### Stage 10 — Polish & README

* Add detailed `README.md` that documents setup, tests, docker build/run, how to use the app (upload → map → edit → validate → export), and known limitations.
* Add code comments, tidy up any TODOs, and ensure consistent formatting.

**Commit:** `docs: finish README and polish code comments`

---

## Commit message examples (Conventional Commits)

* `chore: init repo scaffold`
* `feat(backend): add CSV parsing endpoint`
* `fix(backend): handle missing SubTopic header variants`
* `test(frontend): add EditableTable unit tests`
* `ci: add github action for tests`

Always include a short body (1–2 lines) if the change needs extra explanation.

---

## Git / automation snippets (optional)

If you want to automate commit creation from within Cursor, use a small local script that the LLM can run or suggest. Example helper `scripts/commit-and-push.sh`:

```bash
#!/usr/bin/env bash
set -euo pipefail
MSG="$1"
FILES="$2" # optional: file list to stage
if [ -z "$FILES" ]; then
  git add -A
else
  git add $FILES
fi
# run tests (backend + frontend)
# adjust to your monorepo test commands
npm --prefix backend test || { echo "backend tests failed"; exit 1; }
npm --prefix frontend test || { echo "frontend tests failed"; exit 1; }
# commit
git commit -m "$MSG"
# optional: push
# git push origin HEAD
```

**Important:** do not run commits automatically unless you understand the changes the LLM will make. Prefer manual review-and-accept in Cursor.

---

## Header normalization rules (implementation hints)

* Normalize incoming CSV headers by: trimming, lowercasing, removing spaces/hyphens/underscores.
* Map variants:

  * `subtopic`, `sub_topic`, `sub topic`, `sub-topic` -> `SubTopic`
  * `topic` -> `Topic`
  * `industry` -> `Industry`
  * `classification` -> `Classification`
  * `prompt`, `risks`, `keywords` -> keep original semantic names

Use a canonical keys map in backend parse helper so frontend always receives consistent object keys.

---

## Validation behavior (detailed)

* Build a set of normalized keys from classifications: `normalize(Topic) || '||' || normalize(SubTopic) || '||' || normalize(Industry)`.
* For each strings row, compute the same key; if key not present, mark invalid with reason that includes the raw values.
* `normalize(...)` = `String(value || '').trim().toLowerCase()`.
* If `Topic` or `SubTopic` or `Industry` are missing/blank in strings row treat as invalid and include specific missing-field reason.

When returning invalid rows, include the following JSON fields per invalid row:

```json
{ "rowIndex": 4, "row": { ... }, "reason": "No classification for Topic='Payments', SubTopic='ACH', Industry='Fintech'" }
```

---

## Testing guidance

* **Backend unit tests**: focus on parse/normalize/validate functions. Test edge cases (empty strings, missing headers, duplicate rows).
* **Frontend tests**: test the editable table behavior (editing cells, add/delete), and the validation UI (highlighting invalid rows). Where network calls are involved, mock axios/fetch.
* Aim for a high-level integration test (node-based) that simulates upload -> validate -> export (can be part of E2E later).

